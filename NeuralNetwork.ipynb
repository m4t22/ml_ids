{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import collections\n",
    "import io\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1: 149915, 1: 67713})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "### main dataset ###\n",
    "data = pd.read_csv(\"20151219.txt\", sep = \"\\t\", header = None)\n",
    "data.columns = [\"conn_len\", \"service\", \"src_bytes\", \"dst_bytes\", \"conn_numb\", \"Same_srv_rate\", \"Serror_rate\", \"Srv_serror_rate\", \"Dst_host_count\", \"Dst_host_srv_count\", \"Dst_host_same_src_port_rate\", \"Dst_host_serror_rate\", \"Dst_host_srv_serror_rate\", \"Conn_state\", \"IDS_detection\", \"Malware_detection\", \"Ashula_detection\", \"attack_flag\", \"src_IP\", \"src_port\", \"dst_IP\", \"dst_port\", \"start_time\", \"proto\"]\n",
    "\n",
    "print(Counter(data[\"attack_flag\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 149915, 0: 67713})\n"
     ]
    }
   ],
   "source": [
    "data.loc[:, \"attack_flag\"] = data.loc[:,\"attack_flag\"].replace(-2, -1)\n",
    "data.loc[:, \"attack_flag\"] = data.loc[:, \"attack_flag\"] * -1\n",
    "data.loc[:, \"attack_flag\"] = data.loc[:,\"attack_flag\"].replace(-1, 0)\n",
    "\n",
    "print(Counter(data[\"attack_flag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217628, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing NaNs\n",
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a bit of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## port numbers classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1023  # well-known port numbers\n",
    "t2 = 49151 # registered ports\n",
    "t3 = 65535 # client ports\n",
    "\n",
    "def wk(data_row):\n",
    "    if (data_row[\"src_port\"] <= t1): \n",
    "        value = 1\n",
    "    elif ((data_row[\"src_port\"] > t1) and (data_row[\"src_port\"] <= t2)):\n",
    "        value = 0\n",
    "    elif ((data_row[\"src_port\"] > t2) and (data_row[\"src_port\"] <= t3)):\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def reg(data_row):\n",
    "    if (data_row[\"src_port\"] <= t1): \n",
    "        value = 0\n",
    "    elif ((data_row[\"src_port\"] > t1) and (data_row[\"src_port\"] <= t2)):\n",
    "        value = 1\n",
    "    elif ((data_row[\"src_port\"] > t2) and (data_row[\"src_port\"] <= t3)):\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def cli(data_row):\n",
    "    if (data_row[\"src_port\"] <= t1): \n",
    "        value = 0\n",
    "    elif ((data_row[\"src_port\"] > t1) and (data_row[\"src_port\"] <= t2)):\n",
    "        value = 0\n",
    "    elif ((data_row[\"src_port\"] > t2) and (data_row[\"src_port\"] <= t3)):\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "data[\"well_known_src_pool\"] = data.apply(wk, axis=1)\n",
    "data[\"registered_src_pool\"] = data.apply(reg, axis=1)\n",
    "data[\"cli_src_pool\"] = data.apply(cli, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"src_port\"] = data[\"src_port\"].apply(str)\n",
    "data[\"dst_port\"] = data[\"dst_port\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152339, 27)\n",
      "(32644, 27)\n",
      "(32645, 27)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = np.split(data, [int(.7*len(data)), int(.85*len(data))])\n",
    "train = train.sample(frac=1)\n",
    "validate = validate.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "y_train = train.loc[:, \"attack_flag\"].values.ravel()\n",
    "X_train = train.drop([\"attack_flag\"], axis=1)\n",
    "y_validate = validate.loc[:, \"attack_flag\"].values.ravel()\n",
    "X_validate = validate.drop([\"attack_flag\"], axis=1)\n",
    "y_test = test.loc[:, \"attack_flag\"].values.ravel()\n",
    "X_test = test.drop([\"attack_flag\"], axis=1)\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_numeric_feat = [\"Same_srv_rate\", \"Serror_rate\", \"Srv_serror_rate\", \"Dst_host_count\", \"Dst_host_srv_count\", \"Dst_host_same_src_port_rate\", \"Dst_host_serror_rate\", \"Dst_host_srv_serror_rate\", \"well_known_src_pool\", \"registered_src_pool\", \"cli_src_pool\"]\n",
    "wide_numeric_feat = [\"conn_len\",  \"src_bytes\", \"dst_bytes\", \"conn_numb\"]\n",
    "categorical_feat = [\"service\", \"Conn_state\", \"src_port\", \"dst_port\", \"proto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_numeric_feat_tf = [tf.feature_column.numeric_column(k) for k in deep_numeric_feat]\n",
    "wide_numeric_feat_tf = [tf.feature_column.numeric_column(k) for k in wide_numeric_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"src_port\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_port_mod = [\"src_\" + s for s in data[\"src_port\"].unique().tolist()]\n",
    "src_port = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'src_port', src_port_mod)\n",
    "\n",
    "dst_port_mod = [\"dst_\" + s for s in data[\"dst_port\"].unique().tolist()]\n",
    "dst_port = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'dst_port', dst_port_mod)\n",
    "\n",
    "service = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'service', data[\"service\"].unique().tolist())\n",
    "\n",
    "Conn_state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'Conn_state', data[\"Conn_state\"].unique().tolist())\n",
    "\n",
    "proto = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'proto', data[\"proto\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(service),\n",
    "    tf.feature_column.indicator_column(Conn_state),\n",
    "    tf.feature_column.indicator_column(proto),\n",
    "    tf.feature_column.embedding_column(src_port, dimension=10),\n",
    "    tf.feature_column.embedding_column(dst_port, dimension=3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossed_columns = [\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['src_port', 'service'], hash_bucket_size=10000),\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['service', 'proto'], hash_bucket_size=10000),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/matz/Desktop/ml_ids/NN_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f711382d080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir = \"/home/matz/Desktop/ml_ids/NN_model\",\n",
    "    dnn_activation_fn=tf.nn.selu,\n",
    "    linear_feature_columns = wide_numeric_feat_tf + crossed_columns,\n",
    "    dnn_feature_columns = deep_columns + deep_numeric_feat_tf + wide_numeric_feat_tf,\n",
    "    dnn_hidden_units = [450, 250, 150, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set= deep_numeric_feat + wide_numeric_feat + categorical_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, n_batch = 256, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in feature_set}),\n",
    "       y = pd.Series(data_set[\"attack_flag\"].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.estimator.inputs.pandas_io.pandas_input_fn.<locals>.input_fn()>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input_fn(test, n_batch=test.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/matz/Desktop/ml_ids/NN_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 130.22742, step = 1\n",
      "INFO:tensorflow:global_step/sec: 108.871\n",
      "INFO:tensorflow:loss = 6.921026, step = 101 (0.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.669\n",
      "INFO:tensorflow:loss = 16.337284, step = 201 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.725\n",
      "INFO:tensorflow:loss = 10.442221, step = 301 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.272\n",
      "INFO:tensorflow:loss = 7.821759, step = 401 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.361\n",
      "INFO:tensorflow:loss = 6.4918575, step = 501 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.713\n",
      "INFO:tensorflow:loss = 6.597049, step = 601 (0.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.551\n",
      "INFO:tensorflow:loss = 13.303362, step = 701 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.96\n",
      "INFO:tensorflow:loss = 15.449125, step = 801 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.76\n",
      "INFO:tensorflow:loss = 4.7600846, step = 901 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.178\n",
      "INFO:tensorflow:loss = 4.554931, step = 1001 (0.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.236\n",
      "INFO:tensorflow:loss = 8.045667, step = 1101 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.136\n",
      "INFO:tensorflow:loss = 4.404895, step = 1201 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.545\n",
      "INFO:tensorflow:loss = 2.5100307, step = 1301 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.971\n",
      "INFO:tensorflow:loss = 11.89476, step = 1401 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.56\n",
      "INFO:tensorflow:loss = 2.0913913, step = 1501 (0.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.253\n",
      "INFO:tensorflow:loss = 2.4609888, step = 1601 (0.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.879\n",
      "INFO:tensorflow:loss = 3.2497907, step = 1701 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.483\n",
      "INFO:tensorflow:loss = 7.490576, step = 1801 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.418\n",
      "INFO:tensorflow:loss = 2.2923164, step = 1901 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.583\n",
      "INFO:tensorflow:loss = 5.1278667, step = 2001 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.579\n",
      "INFO:tensorflow:loss = 1.3091953, step = 2101 (0.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.814\n",
      "INFO:tensorflow:loss = 11.301329, step = 2201 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.446\n",
      "INFO:tensorflow:loss = 3.2093616, step = 2301 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.37\n",
      "INFO:tensorflow:loss = 9.223826, step = 2401 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.329\n",
      "INFO:tensorflow:loss = 6.1036215, step = 2501 (0.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.206\n",
      "INFO:tensorflow:loss = 9.307699, step = 2601 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.785\n",
      "INFO:tensorflow:loss = 4.1691523, step = 2701 (0.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.283\n",
      "INFO:tensorflow:loss = 5.5354376, step = 2801 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.784\n",
      "INFO:tensorflow:loss = 3.9532204, step = 2901 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.592\n",
      "INFO:tensorflow:loss = 6.0535564, step = 3001 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.608\n",
      "INFO:tensorflow:loss = 10.412672, step = 3101 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.697\n",
      "INFO:tensorflow:loss = 2.650384, step = 3201 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.621\n",
      "INFO:tensorflow:loss = 4.569434, step = 3301 (0.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.466\n",
      "INFO:tensorflow:loss = 5.3251414, step = 3401 (0.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.128\n",
      "INFO:tensorflow:loss = 9.454144, step = 3501 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.464\n",
      "INFO:tensorflow:loss = 7.278414, step = 3601 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.829\n",
      "INFO:tensorflow:loss = 5.527772, step = 3701 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.961\n",
      "INFO:tensorflow:loss = 4.702362, step = 3801 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.209\n",
      "INFO:tensorflow:loss = 6.987007, step = 3901 (0.792 sec)\n"
     ]
    }
   ],
   "source": [
    "model.train(input_fn=get_input_fn(test, n_batch=256, shuffle=False), steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = model.evaluate(input_fn=get_input_fn(validate, n_batch=validate.shape[0], shuffle=False), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in sorted(eval_metrics.items()):\n",
    "  print('%s: %s' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results = list(model.predict(input_fn=get_input_fn(test, num_epochs=1, n_batch = X_test.shape[0], shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for el in results:\n",
    "    y_pred.append(el[\"class_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"NN\"\n",
    "\n",
    "Acc = {}\n",
    "F1S = {}\n",
    "Prec = {}\n",
    "Rec = {}\n",
    "FPR = {}\n",
    "\n",
    "Acc[name] = metrics.accuracy_score(y_test, y_pred)\n",
    "F1S[name] = metrics.f1_score(y_test, y_pred)\n",
    "Prec[name] = metrics.precision_score(y_test, y_pred)\n",
    "Rec[name] = metrics.recall_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "FPR[name] = fp/(fp+tn)\n",
    "\n",
    "print(\"{0:2} Accuracy: {1:.5f}, F1-score: {2:.5f}, Precision: {3:.5f}, Recall: {4:.5f}, FPR: {5:.5f}\".format(name, Acc[name], F1S[name], Prec[name], Rec[name], FPR[name]))\n",
    "print(\"TN: {0:3}; FP: {1:3}; FN: {2:4}; TP: {3:3}\\n\".format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
